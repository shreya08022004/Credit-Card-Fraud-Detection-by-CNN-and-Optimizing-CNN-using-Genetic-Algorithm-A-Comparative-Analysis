{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgAHFLns36tl",
        "outputId": "7ba3712b-484f-4f26-ed56-0178866cc837"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neE8MoZI4WXs"
      },
      "source": [
        "# Loading the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQ9H6WHK4YzP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,precision_score,recall_score\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from joblib import Parallel, delayed, parallel_backend\n",
        "from tensorflow.keras.backend import clear_session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu_ZINbY4epP"
      },
      "source": [
        "# Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "ulbS-I7d4hGM",
        "outputId": "0fa15c47-dd9c-4ebc-ea45-a4099fa393db"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Major Project/creditcard.csv\")\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uu7GmpW4jT-"
      },
      "source": [
        "# Scale Amount and Time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-GVu8Qh4nc2"
      },
      "outputs": [],
      "source": [
        "df[['Scaled_Time', 'Scaled_Amount']] = StandardScaler().fit_transform(df[['Time', 'Amount']])\n",
        "df = df.drop(['Time', 'Amount'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xo4Zuf-vW_Ig",
        "outputId": "d9f14bbe-16d2-43d4-8d68-72598d6f6386"
      },
      "outputs": [],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNVKaMfV4ozb"
      },
      "source": [
        "# Handling Class Imbalance using SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4LITvBj4sqn",
        "outputId": "eb5eed26-2359-4107-8e85-6c3cb14b6e33"
      },
      "outputs": [],
      "source": [
        "X = df.drop(['Class'], axis=1)\n",
        "y = df['Class']\n",
        "smote = SMOTE(sampling_strategy=0.2, random_state=42)\n",
        "X_res, y_res = smote.fit_resample(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L96du70Nqn6A"
      },
      "source": [
        "# Size of the Dataset after SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-abKvXyqvGN",
        "outputId": "62938c11-672c-4963-a86d-ad9cff572ee0"
      },
      "outputs": [],
      "source": [
        "len(X_res)\n",
        "len(y_res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUA0lFkL4t4F"
      },
      "source": [
        "# Reshape for CNN input after Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyJFccb34yHz"
      },
      "outputs": [],
      "source": [
        "X_res = X_res.values.reshape((X_res.shape[0], X_res.shape[1], 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVs80Wtw4zBZ"
      },
      "source": [
        "# Split the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u23inZkR41pF"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGvwxinbrTaH"
      },
      "source": [
        "# Size of the Train Set and Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPxNCLtirX86",
        "outputId": "f3571a4c-0944-4838-b7b6-8463ef44287c"
      },
      "outputs": [],
      "source": [
        "len(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsjD6awlrle7",
        "outputId": "73e027d2-a7d3-425f-b9be-4d73b5320955"
      },
      "outputs": [],
      "source": [
        "len(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbaRaPb242YT"
      },
      "source": [
        "# Creating the CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ps8xQ3Ms46NN"
      },
      "outputs": [],
      "source": [
        "def create_cnn(filters, kernel_size, learning_rate):\n",
        "    model = keras.Sequential([\n",
        "        layers.Input(shape=(X_train.shape[1], 1)),\n",
        "        layers.Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', padding='same'),\n",
        "        layers.MaxPooling1D(pool_size=2),\n",
        "        layers.Conv1D(filters=filters * 2, kernel_size=kernel_size, activation='relu', padding='same'),\n",
        "        layers.MaxPooling1D(pool_size=2),\n",
        "        layers.Conv1D(filters=filters * 4, kernel_size=kernel_size, activation='relu', padding='same'),\n",
        "        layers.GlobalMaxPooling1D(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=keras.optimizers.AdamW(learning_rate=learning_rate,weight_decay=1e-5),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weCe4qqt47XR"
      },
      "source": [
        "# Function for Adaptive Mutation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxd1Y4L84_XO"
      },
      "outputs": [],
      "source": [
        "def adaptive_mutation(child, generation, max_generations, max_mutation=0.2):\n",
        "    mutation_rate = max_mutation * (1 - (generation / max_generations))\n",
        "    if random.random() < mutation_rate:\n",
        "        child = (\n",
        "            child[0] + random.randint(-8, 8),  # Mutate filters\n",
        "            child[1] + random.randint(-1,-1),  # Keep kernel size\n",
        "            child[2] + random.uniform(-0.001, 0.001)  # Change learning rate slightly\n",
        "        )\n",
        "    return child"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgJWWap05AjW"
      },
      "source": [
        "# Function for Layer-Wise Crossover"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Cu9LOEh5E98"
      },
      "outputs": [],
      "source": [
        "def cnn_layer_crossover(parent1, parent2):\n",
        "    child = (\n",
        "        parent2[0],  # Filters from parent2\n",
        "        parent1[1],  # Kernel size from parent1\n",
        "        (parent1[2] + parent2[2]) / 2  # Average learning rate\n",
        "    )\n",
        "    return child"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwGQUfsz5GI2"
      },
      "source": [
        "# Function for Parallel Fitness Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7Y2ZV6Y5LMX"
      },
      "outputs": [],
      "source": [
        "def parallel_fitness(population):\n",
        "    def evaluate(individual):\n",
        "        filters, kernel_size, learning_rate = individual\n",
        "        model = create_cnn(int(filters), int(kernel_size), learning_rate)\n",
        "\n",
        "        # Adding early stopping and learning rate scheduler\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "        lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
        "\n",
        "        model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=0,\n",
        "                  callbacks=[early_stopping, lr_scheduler], validation_split=0.1)\n",
        "\n",
        "        _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "        return (accuracy, individual)\n",
        "\n",
        "    results = Parallel(n_jobs=2)(delayed(evaluate)(ind) for ind in population)\n",
        "    return sorted(results, key=lambda x: -x[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pI3pV2-z5Mmr"
      },
      "source": [
        "# Function for Initialization of Population"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RbMngrx5Som"
      },
      "outputs": [],
      "source": [
        "def initialize_population(size):\n",
        "    population = []\n",
        "    for _ in range(size):\n",
        "        filters = random.randint(16, 64)\n",
        "        kernel_size = random.randint(2, 5)\n",
        "        learning_rate = random.uniform(0.001, 0.01)\n",
        "        population.append((filters, kernel_size, learning_rate))\n",
        "    return population"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PrAQCIJ5UVC"
      },
      "source": [
        "# Genetic Algorithm Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xkim1XhN5XGI",
        "outputId": "ba8619e8-224c-4e23-a0df-cc8a71fadeb7"
      },
      "outputs": [],
      "source": [
        "population_size = 20\n",
        "generations = 10\n",
        "population = initialize_population(population_size)\n",
        "\n",
        "for generation in range(generations):\n",
        "    print(f\"Generation: {generation + 1}\")\n",
        "    fitness_results = parallel_fitness(population)\n",
        "\n",
        "    # Select top individuals\n",
        "    top_individuals = [ind for _, ind in fitness_results[:population_size // 2]]\n",
        "\n",
        "    # Crossover to create new population\n",
        "    new_population = []\n",
        "    for i in range(0, len(top_individuals), 2):\n",
        "        parent1 = top_individuals[i % len(top_individuals)]\n",
        "        parent2 = top_individuals[(i + 1) % len(top_individuals)]\n",
        "        child = cnn_layer_crossover(parent1, parent2)\n",
        "        new_population.append(child)\n",
        "\n",
        "    # Apply mutation\n",
        "    new_population = [adaptive_mutation(child, generation, generations) for child in new_population]\n",
        "    population = new_population"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwskuhph5aCd"
      },
      "source": [
        "# Final Evaluation of the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-vL-rGK5el7",
        "outputId": "8413193c-349f-4eb8-a79d-e03ad419a95a"
      },
      "outputs": [],
      "source": [
        "best_model = create_cnn(*fitness_results[0][1])\n",
        "best_model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=1)\n",
        "y_predicted = (best_model.predict(X_test) > 0.5).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2SanWr95fr2"
      },
      "source": [
        "# Accuracy, Confusion Matrix and Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIJp9hFl5lmh",
        "outputId": "39582238-4946-475a-8ce5-e51a9b925efa"
      },
      "outputs": [],
      "source": [
        "print('Classification report:\\n', classification_report(y_test, y_predicted))\n",
        "cm = confusion_matrix(y_true=y_test, y_pred=y_predicted)\n",
        "print('Confusion matrix:\\n', cm)\n",
        "print('Accuracy:', accuracy_score(y_test, y_predicted))\n",
        "precision = precision_score(y_test, y_predicted, pos_label=1.0)\n",
        "print('precision : ',precision)\n",
        "recall = recall_score(y_test, y_predicted, pos_label=1.0)\n",
        "print('recall rate : ',recall)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pbyc9u8x5mon"
      },
      "source": [
        "# Saving the model metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "P4ZN48Pj5p4Y",
        "outputId": "099e817e-faab-496b-f3eb-54e3a2b08c42"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "output_path=\"/content/drive/MyDrive/Major Project/Model_Outputs\"\n",
        "os.makedirs(output_path,exist_ok=True)\n",
        "#Saving the best model\n",
        "model_save_path=os.path.join(output_path,\"best_model.keras\")\n",
        "best_model.save(model_save_path)\n",
        "print(\"Model saved at:\",model_save_path)\n",
        "#Saving the predicted output\n",
        "y_predicted=(best_model.predict(X_test)>0.5).astype(int)\n",
        "#Saving the classification report and confusion matrix\n",
        "report=classification_report(y_test,y_predicted)\n",
        "cm=confusion_matrix(y_true=y_test,y_pred=y_predicted)\n",
        "accuracy=accuracy_score(y_test,y_predicted)\n",
        "\n",
        "output_file=os.path.join(output_path,\"model_metrics.txt\")\n",
        "with open(output_file, \"w\") as f:\n",
        "  f.write(\"Classification Report:\\n\")\n",
        "  f.write(report)\n",
        "  f.write(\"\\nConfusion Matrix:\\n\")\n",
        "  f.write(str(cm))\n",
        "  f.write(f\"\\nAccuracy:{accuracy:.4f}\")\n",
        "  f.write(f\"\\nPrecision:{precision:.4f}\")\n",
        "  f.write(f\"\\nRecall:{recall:.4f}\")\n",
        "print(f\"Metrics saved at:{output_file}\")\n",
        "#saving confusion matrix as plot\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm,annot=True,fmt='d',cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "conf_matrix_path=os.path.join(output_path,'confusion_matrix.png')\n",
        "plt.savefig(conf_matrix_path)\n",
        "print(f\"Confusion matrix plot save at:{conf_matrix_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWadlByv5q7Z"
      },
      "source": [
        "# Loading the Saved Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZxHvULxm5tuF",
        "outputId": "042227f4-8113-4e75-a6fb-7b4a9a302672"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "from joblib import load\n",
        "import os\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,precision_score,recall_score, roc_auc_score,roc_curve,precision_recall_curve,auc,roc_curve,f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the saved model from Google Drive\n",
        "model_path = \"/content/drive/MyDrive/Major Project/Model_Outputs/best_model.keras\"\n",
        "loaded_model = load_model(model_path)\n",
        "\n",
        "# Check the model architecture\n",
        "loaded_model.summary()\n",
        "\n",
        "# Use the loaded model to make predictions\n",
        "y_pred = (loaded_model.predict(X_test) > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the model with test data\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "print('Classification Report:\\n', classification_report(y_test, y_pred))\n",
        "cm=confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
        "print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred))\n",
        "accuracy=accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, pos_label=1.0)\n",
        "recall = recall_score(y_test, y_pred, pos_label=1.0)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.3f}\")\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall: {recall:.3f}\")\n",
        "print(f\"F1-Score: {f1:.3f}\")\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "# AUC-ROC Curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', label=f'ROC Curve (AUC = {roc_auc:.3f})')\n",
        "plt.title('AUC-ROC Curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# AUC-PRC Curve\n",
        "precision_pr, recall_pr, _ = precision_recall_curve(y_test, y_pred)\n",
        "pr_auc = auc(recall_pr, precision_pr)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall_pr, precision_pr, color='purple', lw=2, label=f'PR Curve (AUC = {pr_auc:.3f})')\n",
        "plt.title('AUC-PRC Curve')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
