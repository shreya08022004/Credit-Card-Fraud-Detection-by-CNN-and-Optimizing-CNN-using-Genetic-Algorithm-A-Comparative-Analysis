{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8p7NI1ueDMY2",
        "outputId": "5a9c4c44-5a36-4f1d-9431-05030cac250d"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SqpVeH7DTon"
      },
      "source": [
        "# Loading the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkZQELtuDXpI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,precision_score,recall_score\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from joblib import Parallel, delayed, parallel_backend\n",
        "from tensorflow.keras.backend import clear_session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHTWmrxaDYxQ"
      },
      "source": [
        "# Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "3hupLC7aDdCI",
        "outputId": "1397d879-ebc7-4795-93e6-60a5b3fad865"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Major Project/creditcard.csv\")\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOsIk4dkDfEl"
      },
      "source": [
        "# Scale Amount and Time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVIFO5QUDhx3"
      },
      "outputs": [],
      "source": [
        "df[['Scaled_Time', 'Scaled_Amount']] = StandardScaler().fit_transform(df[['Time', 'Amount']])\n",
        "df = df.drop(['Time', 'Amount'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VE2WrKcIDlEi"
      },
      "outputs": [],
      "source": [
        "X = df.drop(['Class'], axis=1)\n",
        "y = df['Class']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZuX3iKqDl31"
      },
      "source": [
        "# Splitting the Dataset into Train and Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsLqLQILDp2x"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlJZs6qtDtlH"
      },
      "source": [
        "# Creating the CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqX8A5bwDvp6"
      },
      "outputs": [],
      "source": [
        "def create_cnn(filters, kernel_size, learning_rate):\n",
        "    model = keras.Sequential([\n",
        "        layers.Input(shape=(X_train.shape[1], 1)),\n",
        "        layers.Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', padding='same'),\n",
        "        layers.MaxPooling1D(pool_size=2),\n",
        "        layers.Conv1D(filters=filters * 2, kernel_size=kernel_size, activation='relu', padding='same'),\n",
        "        layers.MaxPooling1D(pool_size=2),\n",
        "        layers.Conv1D(filters=filters * 4, kernel_size=kernel_size, activation='relu', padding='same'),\n",
        "        layers.GlobalMaxPooling1D(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=keras.optimizers.AdamW(learning_rate=learning_rate,weight_decay=1e-5),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7iazDiuDzV4"
      },
      "source": [
        "# Function for Adaptive Mutation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ej15Ps0qD3sv"
      },
      "outputs": [],
      "source": [
        "def adaptive_mutation(child, generation, max_generations, max_mutation=0.2):\n",
        "    mutation_rate = max_mutation * (1 - (generation / max_generations))\n",
        "    if random.random() < mutation_rate:\n",
        "        child = (\n",
        "            child[0] + random.randint(-8, 8),  # Mutate filters\n",
        "            child[1] + random.randint(-1,-1),  # Keep kernel size\n",
        "            child[2] + random.uniform(-0.001, 0.001)  # Change learning rate slightly\n",
        "        )\n",
        "    return child"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4m3goSelD93z"
      },
      "source": [
        "# Function for Layer-Wise Crossover"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_uzzgWNEJ-3"
      },
      "outputs": [],
      "source": [
        "def cnn_layer_crossover(parent1, parent2):\n",
        "    child = (\n",
        "        parent2[0],  # Filters from parent2\n",
        "        parent1[1],  # Kernel size from parent1\n",
        "        (parent1[2] + parent2[2]) / 2  # Average learning rate\n",
        "    )\n",
        "    return child"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCiz60xfELjZ"
      },
      "source": [
        "# Function for Parallel Fitness Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jexZxeJcEO_e"
      },
      "outputs": [],
      "source": [
        "def parallel_fitness(population):\n",
        "    def evaluate(individual):\n",
        "        filters, kernel_size, learning_rate = individual\n",
        "        model = create_cnn(int(filters), int(kernel_size), learning_rate)\n",
        "\n",
        "        # Adding early stopping and learning rate scheduler\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "        lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
        "\n",
        "        model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=0,\n",
        "                  callbacks=[early_stopping, lr_scheduler], validation_split=0.1)\n",
        "\n",
        "        _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "        return (accuracy, individual)\n",
        "\n",
        "    results = Parallel(n_jobs=2)(delayed(evaluate)(ind) for ind in population)\n",
        "    return sorted(results, key=lambda x: -x[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Htem808ERSV"
      },
      "source": [
        "# Function for Initilization of Population"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-L1FWhUrETxv"
      },
      "outputs": [],
      "source": [
        "def initialize_population(size):\n",
        "    population = []\n",
        "    for _ in range(size):\n",
        "        filters = random.randint(16, 64)\n",
        "        kernel_size = random.randint(2, 5)\n",
        "        learning_rate = random.uniform(0.001, 0.01)\n",
        "        population.append((filters, kernel_size, learning_rate))\n",
        "    return population"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSq_ejTQEdyY"
      },
      "source": [
        "# Genetic Algorithm Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-KuX4F1EhFl",
        "outputId": "c44dd5a1-95d5-48f7-e927-cf1344d4a012"
      },
      "outputs": [],
      "source": [
        "population_size = 20\n",
        "generations = 10\n",
        "population = initialize_population(population_size)\n",
        "\n",
        "for generation in range(generations):\n",
        "    print(f\"Generation: {generation + 1}\")\n",
        "    fitness_results = parallel_fitness(population)\n",
        "\n",
        "    # Select top individuals\n",
        "    top_individuals = [ind for _, ind in fitness_results[:population_size // 2]]\n",
        "\n",
        "    # Crossover to create new population\n",
        "    new_population = []\n",
        "    for i in range(0, len(top_individuals), 2):\n",
        "        parent1 = top_individuals[i % len(top_individuals)]\n",
        "        parent2 = top_individuals[(i + 1) % len(top_individuals)]\n",
        "        child = cnn_layer_crossover(parent1, parent2)\n",
        "        new_population.append(child)\n",
        "\n",
        "    # Apply mutation\n",
        "    new_population = [adaptive_mutation(child, generation, generations) for child in new_population]\n",
        "    population = new_population"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8FBAmJ_EjtC"
      },
      "source": [
        "# Final Evaluation of Best Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8YkiIG8En4u",
        "outputId": "bab873be-12ed-475b-9eb0-68c168680c0d"
      },
      "outputs": [],
      "source": [
        "best_model = create_cnn(*fitness_results[0][1])\n",
        "best_model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=1)\n",
        "y_predicted = (best_model.predict(X_test) > 0.5).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZwXA043EtRz"
      },
      "source": [
        "# Accuracy, Confusion Matrix and Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTDnYyyWEx5H",
        "outputId": "859eebfc-0cc7-40fc-c2c4-8f3235446ce3"
      },
      "outputs": [],
      "source": [
        "print('Classification report:\\n', classification_report(y_test, y_predicted))\n",
        "cm = confusion_matrix(y_true=y_test, y_pred=y_predicted)\n",
        "print('Confusion matrix:\\n', cm)\n",
        "print('Accuracy:', accuracy_score(y_test, y_predicted))\n",
        "precision = precision_score(y_test, y_predicted, pos_label=1.0)\n",
        "print('precision : ',precision)\n",
        "recall = recall_score(y_test, y_predicted, pos_label=1.0)\n",
        "print('recall rate : ',recall)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZmTWVIxSUvh"
      },
      "source": [
        "# Saving the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "Q59fKiWxSYjB",
        "outputId": "8ef8ed88-d95d-4c8f-fff3-092a0446316b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "output_path=\"/content/drive/MyDrive/Major Project/Model_Outputs\"\n",
        "os.makedirs(output_path,exist_ok=True)\n",
        "#Saving the best model\n",
        "model_save_path=os.path.join(output_path,\"ns_best_model.keras\")\n",
        "best_model.save(model_save_path)\n",
        "print(\"Model saved at:\",model_save_path)\n",
        "#Saving the predicted output\n",
        "y_predicted=(best_model.predict(X_test)>0.5).astype(int)\n",
        "#Saving the classification report and confusion matrix\n",
        "report=classification_report(y_test,y_predicted)\n",
        "cm=confusion_matrix(y_true=y_test,y_pred=y_predicted)\n",
        "accuracy=accuracy_score(y_test,y_predicted)\n",
        "\n",
        "output_file=os.path.join(output_path,\"ns_model_metrics.txt\")\n",
        "with open(output_file, \"w\") as f:\n",
        "  f.write(\"Classification Report:\\n\")\n",
        "  f.write(report)\n",
        "  f.write(\"\\nConfusion Matrix:\\n\")\n",
        "  f.write(str(cm))\n",
        "  f.write(f\"\\nAccuracy:{accuracy:.4f}\")\n",
        "  f.write(f\"\\nPrecision:{precision:.4f}\")\n",
        "  f.write(f\"\\nRecall:{recall:.4f}\")\n",
        "print(f\"Metrics saved at:{output_file}\")\n",
        "#saving confusion matrix as plot\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm,annot=True,fmt='d',cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "conf_matrix_path=os.path.join(output_path,'ns_confusion_matrix.png')\n",
        "plt.savefig(conf_matrix_path)\n",
        "print(f\"Confusion matrix plot save at:{conf_matrix_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYokMb9dhheu"
      },
      "source": [
        "# Loading the Saved Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1BG0wwBVhkcR",
        "outputId": "cb432668-701f-42e6-de81-22466e7646c5"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "from joblib import load\n",
        "import os\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,precision_score,recall_score, roc_auc_score,roc_curve,precision_recall_curve,auc,roc_curve,f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the saved model from Google Drive\n",
        "model_path = \"/content/drive/MyDrive/Major Project/Model_Outputs/ns_best_model.keras\"\n",
        "loaded_model = load_model(model_path)\n",
        "\n",
        "# Check the model architecture\n",
        "loaded_model.summary()\n",
        "\n",
        "# Use the loaded model to make predictions\n",
        "y_pred = (loaded_model.predict(X_test) > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the model with test data\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "print('Classification Report:\\n', classification_report(y_test, y_pred))\n",
        "cm=confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
        "print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred))\n",
        "accuracy=accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, pos_label=1.0)\n",
        "recall = recall_score(y_test, y_pred, pos_label=1.0)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.3f}\")\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall: {recall:.3f}\")\n",
        "print(f\"F1-Score: {f1:.3f}\")\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "# AUC-ROC Curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', label=f'ROC Curve (AUC = {roc_auc:.3f})')\n",
        "plt.title('AUC-ROC Curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# AUC-PRC Curve\n",
        "precision_pr, recall_pr, _ = precision_recall_curve(y_test, y_pred)\n",
        "pr_auc = auc(recall_pr, precision_pr)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall_pr, precision_pr, color='purple', lw=2, label=f'PR Curve (AUC = {pr_auc:.3f})')\n",
        "plt.title('AUC-PRC Curve')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
